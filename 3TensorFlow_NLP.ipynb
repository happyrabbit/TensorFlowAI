{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3TensorFlow_NLP ",
      "provenance": [],
      "authorship_tag": "ABX9TyNxIRZJDZLsncIIpkC/XC42",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/happyrabbit/TensorFlowAI/blob/master/3TensorFlow_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyNe1WLN6kL5",
        "colab_type": "text"
      },
      "source": [
        "# Natural Language Processing in TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5gfpUdWUxzy",
        "colab_type": "text"
      },
      "source": [
        "## Week 1 - Lesson 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpezojJMgOhM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "0290be99-bc0f-411d-91c9-f7f2d0010036"
      },
      "source": [
        "# Load packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X-RoZ0p7Vxv",
        "colab_type": "text"
      },
      "source": [
        "Here's the code to encode the two sentences. Tensorflow and keras give us a number of ways to encode words. We are going to use `tokenizer` here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOPoEad1h347",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ['I love my dog', 'i love my cat']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbWKga_OiisY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ac5ce5c-3409-41a4-da97-04fb925791c3"
      },
      "source": [
        "tokenizer = Tokenizer(num_words = 20)\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F86dRvDU4pH",
        "colab_type": "text"
      },
      "source": [
        "## Week 1 - Lesson 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdZAB8S5i6sL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load packages\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2F-M8C-VfyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences = ['I love my dog', 'i love my cat', 'this moive is great!','I hope the virus can be controlled soon.', 'how long do you think it will last?']\n",
        "tokenizer = Tokenizer(num_words= 100, oov_token= \"<oov>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences, maxlen=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH2t0JyfWxn6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "85b71a9b-ecc3-4d7d-f52d-8fc51a7035a6"
      },
      "source": [
        "print(\"\\nWord Index = \", word_index)\n",
        "print(\"\\nSequences = \", sequences)\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Word Index =  {'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5, 'this': 6, 'moive': 7, 'is': 8, 'great': 9, 'hope': 10, 'the': 11, 'virus': 12, 'can': 13, 'be': 14, 'controlled': 15, 'soon': 16, 'how': 17, 'long': 18, 'do': 19, 'you': 20, 'think': 21, 'it': 22, 'will': 23, 'last': 24}\n",
            "\n",
            "Sequences =  [[1, 2, 3, 4], [1, 2, 3, 5], [6, 7, 8, 9], [1, 10, 11, 12, 13, 14, 15, 16], [17, 18, 19, 20, 21, 22, 23, 24]]\n",
            "\n",
            "Padded Sequences:\n",
            "[[ 0  1  2  3  4]\n",
            " [ 0  1  2  3  5]\n",
            " [ 0  6  7  8  9]\n",
            " [12 13 14 15 16]\n",
            " [20 21 22 23 24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xByCBaztqmK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ba5519e0-6d3f-48d9-e355-7ae756c8a64e"
      },
      "source": [
        "# try with words that the tokenizer wasn't fit to\n",
        "test_data = ['what is randomness?', 'Generate a random sequence of events']\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nText Sequence = \", test_seq)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Text Sequence =  [[8], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjVkZnTor2Vr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "c9577357-10ac-4dc9-c90e-c0d6e8513941"
      },
      "source": [
        "\n",
        "padded = pad_sequences(test_seq, maxlen = 10)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "print(padded)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padded Test Sequence: \n",
            "[[0 0 0 0 0 0 0 1 9 1]\n",
            " [0 0 0 0 1 1 1 1 1 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D91h1PRWshpT",
        "colab_type": "text"
      },
      "source": [
        "## Week 1 - Lesson 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Gw-yhssR1X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "76936e94-80b5-4d89-e489-c60f605b335a"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json \\\n",
        "    -O /tmp/sarcasm.json"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-16 03:53:05--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.216.128, 2607:f8b0:400c:c02::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.216.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘/tmp/sarcasm.json’\n",
            "\n",
            "\r/tmp/sarcasm.json     0%[                    ]       0  --.-KB/s               \r/tmp/sarcasm.json   100%[===================>]   5.38M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-03-16 03:53:06 (147 MB/s) - ‘/tmp/sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wj-T3q6AxGF2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "with open(\"/tmp/sarcasm.json\",\"r\") as f:\n",
        "  datastore = json.load(f)\n",
        "\n",
        "sentences = []\n",
        "labels = []\n",
        "urls = []\n",
        "for item in datastore:\n",
        "  sentences.append(item['headline'])\n",
        "  labels.append(item['is_sarcastic'])\n",
        "  urls.append(item['article_link'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8Z7UYjQ7zeC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8485925d-2b8d-4345-ada8-d05334d06cd9"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "tokenizer = Tokenizer(oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print(len(word_index))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29657\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-Et_Qs48c9J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "187bcad1-31d0-4675-ca59-1268139cf53f"
      },
      "source": [
        "# print(word_index)\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "padded = pad_sequences(sequences, padding = \"post\")\n",
        "print(sentences[2])\n",
        "print(padded[2])\n",
        "print(padded.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this moive is great!\n",
            "[6 7 8 9 0 0 0 0]\n",
            "(5, 8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zow_mZ74eSqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}